{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import blosum as bl\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NO_PEPTIDES_IN_CSV = 10\n",
    "FOUR_DIGIT = True\n",
    "\n",
    "ALLELE_SPECIFIC = False\n",
    "\n",
    "project_data = pd.read_csv('../../DATA/allele-associated-dataset-multi-specific.csv', sep='\\t')\n",
    "\n",
    "project_data = project_data[project_data['Allele'].str.contains('A|B|C')]\n",
    "\n",
    "#get the 188 alleles\n",
    "alleles = project_data['Allele'].unique()\n",
    "logging.info(f'amount of alleles in dataset: {len(alleles)}')\n",
    "protein_lengths = project_data['Peptide'].str.len().unique()\n",
    "protein_lengths.sort()\n",
    "# Only take peptides with length 8 to 13\n",
    "project_data = project_data[project_data['Peptide'].str.len().between(8, 13)]\n",
    "\n",
    "project_data = project_data.groupby('Allele').filter(lambda x: len(x) >= NO_PEPTIDES_IN_CSV)\n",
    "#make counter of how many peptides per allele\n",
    "allele_counts = project_data['Allele'].value_counts()\n",
    "print(allele_counts)\n",
    "\n",
    "#Make input of RF same length by selecting first 4 and last 4 amino acids to catch anchor positions\n",
    "def take_first_and_last_four(s):\n",
    "        return s[:4] + s[-4:]\n",
    "\n",
    "project_data['Peptide'] = project_data['Peptide'].apply(take_first_and_last_four)\n",
    "\n",
    "train_sequences = project_data.copy()\n",
    "\n",
    "if ALLELE_SPECIFIC:\n",
    "     train_sequences.columns = ['label', 'sequence']\n",
    "else:\n",
    "    train_sequences.columns = ['label', 'sequence', 'source']\n",
    "     \n",
    "train_sequences\n",
    "\n",
    "#drop all columns in train_sequences that dont start with a or b\n",
    "#train_sequences = train_sequences[train_sequences['label'].str.startswith('A') | train_sequences['label'].str.startswith('B') ]\n",
    "\n",
    "peptide_sequences = list(train_sequences['sequence'].values)\n",
    "hla_alleles = list(train_sequences['label'].values)\n",
    "\n",
    "#One Hot Encoding\n",
    "'''onehot_encoder = OneHotEncoder(sparse=False)\n",
    "X = onehot_encoder.fit_transform([[aa] for seq in peptide_sequences for aa in seq])\n",
    "X = X.reshape(len(peptide_sequences), -1)'''\n",
    "\n",
    "#BLOSUM\n",
    "def encode_aa_blosum(aa: str):\n",
    "    return list(bl.BLOSUM(62)[aa].values())\n",
    "def encode_protein_blosum(p: str):\n",
    "    return np.concatenate([encode_aa_blosum(aa) for aa in p])\n",
    "project_data['Peptide'] = project_data['Peptide'].apply(encode_protein_blosum)\n",
    "\n",
    "X = np.array(list(project_data['Peptide'].values))\n",
    "X = X.reshape(len(peptide_sequences), -1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, hla_alleles, test_size=0.2, random_state=42, stratify=hla_alleles)\n",
    "\n",
    "logging.info(\"we have {} training samples and {} test samples\".format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=None)\n",
    "\n",
    "# Perform cross-validation with 5 folds\n",
    "cv_scores = cross_val_score(rf_classifier, X_train, y_train, cv=5, n_jobs=None)\n",
    "\n",
    "# Print cross-validation scores\n",
    "logging.info(f\"Cross-validation scores: {cv_scores}\")\n",
    "logging.info(f\"Mean CV accuracy: {np.mean(cv_scores)}\")\n",
    "\n",
    "# Fit the classifier on the entire training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {np.round(accuracy, 2)}\")\n",
    "\n",
    "#f1 score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 score:\", np.round(f1,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##save \\n\\nNO_PEPTIDES_IN_CSV = 10\\nFOUR_DIGIT = True\\n\\nALLELE_SPECIFIC = True\\n\\nproject_data = pd.read_csv(\\'all_binder_allele_specific.csv\\', sep=\\'\\t\\')\\n\\nproject_data = project_data[project_data[\\'Allele\\'].str.contains(\\'A|B|C\\')]\\n\\n#get the 188 alleles\\nalleles = project_data[\\'Allele\\'].unique()\\nlogging.info(f\\'amount of alleles in dataset: {len(alleles)}\\')\\nprotein_lengths = project_data[\\'Peptide\\'].str.len().unique()\\nprotein_lengths.sort()\\n# Only take peptides with length 8 to 13\\nproject_data = project_data[project_data[\\'Peptide\\'].str.len().between(8, 13)]\\n\\nproject_data = project_data.groupby(\\'Allele\\').filter(lambda x: len(x) >= NO_PEPTIDES_IN_CSV)\\n#make counter of how many peptides per allele\\nallele_counts = project_data[\\'Allele\\'].value_counts()\\nprint(allele_counts)\\n\\n#Make input of RF same length by selecting first 4 and last 4 amino acids to catch anchor positions\\ndef take_first_and_last_four(s):\\n        return s[:4] + s[-4:]\\n\\nproject_data[\\'Peptide\\'] = project_data[\\'Peptide\\'].apply(take_first_and_last_four)\\ntrain_sequences = project_data.copy()\\n\\nif ALLELE_SPECIFIC:\\n     train_sequences.columns = [\\'label\\', \\'sequence\\']\\nelse:\\n    train_sequences.columns = [\\'label\\', \\'sequence\\', \\'source\\']\\n     \\ntrain_sequences\\n\\n#drop all columns in train_sequences that dont start with a or b\\ntrain_sequences = train_sequences[train_sequences[\\'label\\'].str.startswith(\\'A\\') | train_sequences[\\'label\\'].str.startswith(\\'B\\')]\\n\\npeptide_sequences = list(train_sequences[\\'sequence\\'].values)\\nhla_alleles = list(train_sequences[\\'label\\'].values)\\n\\n#Encoding\\nonehot_encoder = OneHotEncoder(sparse=False)\\nX = onehot_encoder.fit_transform([[aa] for seq in peptide_sequences for aa in seq])\\nX = X.reshape(len(peptide_sequences), -1)\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, hla_alleles, test_size=0.2, random_state=42, stratify=hla_alleles)\\n\\nlogging.info(\"we have {} training samples and {} test samples\".format(X_train.shape[0], X_test.shape[0]))\\n\\nrf_classifier_save = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=None)\\n\\n# Perform cross-validation with 5 folds\\ncv_scores = cross_val_score(rf_classifier_save, X_train, y_train, cv=5, n_jobs=None)\\n\\n# Print cross-validation scores\\nlogging.info(f\"Cross-validation scores: {cv_scores}\")\\nlogging.info(f\"Mean CV accuracy: {np.mean(cv_scores)}\")\\n\\n# Fit the classifier on the entire training data\\nrf_classifier_save.fit(X_train, y_train)\\n\\n# Make predictions on the test data\\ny_pred = rf_classifier_save.predict(X_test)\\n\\n# Evaluate the model\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f\"Accuracy: {np.round(accuracy, 2)}\")\\n\\n#f1 score\\nf1 = f1_score(y_test, y_pred, average=\\'weighted\\')\\nprint(\"F1 score:\", np.round(f1,2))\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''##save \n",
    "\n",
    "NO_PEPTIDES_IN_CSV = 10\n",
    "FOUR_DIGIT = True\n",
    "\n",
    "ALLELE_SPECIFIC = True\n",
    "\n",
    "project_data = pd.read_csv('all_binder_allele_specific.csv', sep='\\t')\n",
    "\n",
    "project_data = project_data[project_data['Allele'].str.contains('A|B|C')]\n",
    "\n",
    "#get the 188 alleles\n",
    "alleles = project_data['Allele'].unique()\n",
    "logging.info(f'amount of alleles in dataset: {len(alleles)}')\n",
    "protein_lengths = project_data['Peptide'].str.len().unique()\n",
    "protein_lengths.sort()\n",
    "# Only take peptides with length 8 to 13\n",
    "project_data = project_data[project_data['Peptide'].str.len().between(8, 13)]\n",
    "\n",
    "project_data = project_data.groupby('Allele').filter(lambda x: len(x) >= NO_PEPTIDES_IN_CSV)\n",
    "#make counter of how many peptides per allele\n",
    "allele_counts = project_data['Allele'].value_counts()\n",
    "print(allele_counts)\n",
    "\n",
    "#Make input of RF same length by selecting first 4 and last 4 amino acids to catch anchor positions\n",
    "def take_first_and_last_four(s):\n",
    "        return s[:4] + s[-4:]\n",
    "\n",
    "project_data['Peptide'] = project_data['Peptide'].apply(take_first_and_last_four)\n",
    "train_sequences = project_data.copy()\n",
    "\n",
    "if ALLELE_SPECIFIC:\n",
    "     train_sequences.columns = ['label', 'sequence']\n",
    "else:\n",
    "    train_sequences.columns = ['label', 'sequence', 'source']\n",
    "     \n",
    "train_sequences\n",
    "\n",
    "#drop all columns in train_sequences that dont start with a or b\n",
    "train_sequences = train_sequences[train_sequences['label'].str.startswith('A') | train_sequences['label'].str.startswith('B')]\n",
    "\n",
    "peptide_sequences = list(train_sequences['sequence'].values)\n",
    "hla_alleles = list(train_sequences['label'].values)\n",
    "\n",
    "#Encoding\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "X = onehot_encoder.fit_transform([[aa] for seq in peptide_sequences for aa in seq])\n",
    "X = X.reshape(len(peptide_sequences), -1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, hla_alleles, test_size=0.2, random_state=42, stratify=hla_alleles)\n",
    "\n",
    "logging.info(\"we have {} training samples and {} test samples\".format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "rf_classifier_save = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=None)\n",
    "\n",
    "# Perform cross-validation with 5 folds\n",
    "cv_scores = cross_val_score(rf_classifier_save, X_train, y_train, cv=5, n_jobs=None)\n",
    "\n",
    "# Print cross-validation scores\n",
    "logging.info(f\"Cross-validation scores: {cv_scores}\")\n",
    "logging.info(f\"Mean CV accuracy: {np.mean(cv_scores)}\")\n",
    "\n",
    "# Fit the classifier on the entire training data\n",
    "rf_classifier_save.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier_save.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {np.round(accuracy, 2)}\")\n",
    "\n",
    "#f1 score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 score:\", np.round(f1,2))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation on TueDB (with 4-digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_peptide_list(peptides):\n",
    "    peptides = [p[:4] + p[-4:] for p in peptides] \n",
    "\n",
    "    '''ex_encoded = onehot_encoder.transform([[aa] for seq in peptides for aa in seq])\n",
    "    ex_encoded_reshaped = ex_encoded.reshape(len(peptides), -1)'''\n",
    "    ex_encoded = np.array([encode_protein_blosum(p) for p in peptides])\n",
    "    ex_encoded_reshaped = ex_encoded.reshape(len(peptides), -1)\n",
    "\n",
    "    prediction = rf_classifier.predict(ex_encoded_reshaped)\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>donor_code</th>\n",
       "      <th>peptide_sequence</th>\n",
       "      <th>alleles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04-001</td>\n",
       "      <td>[TTDLFGRDLSY, AYLEAHETF, NRFQIATV, TAASRLVTL, ...</td>\n",
       "      <td>['A0101', 'A2402', 'B0801', 'B1402', 'C0701', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>[DAVTAFESI, PIDGNFFTY, FLSFMNTEL, YTWEEVFRV, T...</td>\n",
       "      <td>['A0101', 'A0201', 'B5101', 'B5701', 'C0401', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1008</td>\n",
       "      <td>[SLFEEMLQV, TLIDLPGITKV, VVYEGQLISI, AEFKEAFQL...</td>\n",
       "      <td>['A0101', 'A0201', 'B0801', 'B4001', 'C0304', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1010</td>\n",
       "      <td>[ALWSLPLYL, FLLPILSQI, DAYVILKTV, IYEPNFIFF, L...</td>\n",
       "      <td>['A0201', 'A2402', 'B5001', 'B5101', 'C0102', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1012</td>\n",
       "      <td>[TLLPLRVFL, VLWDRTFSLF, SLLDIIEKV, SRLPVLLLL, ...</td>\n",
       "      <td>['A0201', 'A0301', 'B0702', 'B4402', 'C0501', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  donor_code                                   peptide_sequence  \\\n",
       "0     04-001  [TTDLFGRDLSY, AYLEAHETF, NRFQIATV, TAASRLVTL, ...   \n",
       "1       1003  [DAVTAFESI, PIDGNFFTY, FLSFMNTEL, YTWEEVFRV, T...   \n",
       "2       1008  [SLFEEMLQV, TLIDLPGITKV, VVYEGQLISI, AEFKEAFQL...   \n",
       "3       1010  [ALWSLPLYL, FLLPILSQI, DAYVILKTV, IYEPNFIFF, L...   \n",
       "4       1012  [TLLPLRVFL, VLWDRTFSLF, SLLDIIEKV, SRLPVLLLL, ...   \n",
       "\n",
       "                                             alleles  \n",
       "0  ['A0101', 'A2402', 'B0801', 'B1402', 'C0701', ...  \n",
       "1  ['A0101', 'A0201', 'B5101', 'B5701', 'C0401', ...  \n",
       "2  ['A0101', 'A0201', 'B0801', 'B4001', 'C0304', ...  \n",
       "3  ['A0201', 'A2402', 'B5001', 'B5101', 'C0102', ...  \n",
       "4  ['A0201', 'A0301', 'B0702', 'B4402', 'C0501', ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH_TO_TUEDB = '../db_dump_311023_cleaned.tsv'\n",
    "\n",
    "tuedb_df = pd.read_csv(PATH_TO_TUEDB, sep='\\t',index_col=0)\n",
    "\n",
    "tdb_df = tuedb_df.copy()\n",
    "\n",
    "#get all unique alleles\n",
    "alleles = tdb_df['all_hla_alleles_donor'].explode().unique()\n",
    "donors = tdb_df['donor_code'].unique()\n",
    "tdb_df = tdb_df.sort_values(by=['donor_code'])\n",
    "group1_df = tdb_df.groupby('donor_code')['peptide_sequence'].apply(list).reset_index()\n",
    "group1_df['alleles'] = tdb_df.groupby('donor_code')['all_hla_alleles_donor'].apply(list).reset_index()['all_hla_alleles_donor']\n",
    "group1_df['alleles'] = group1_df['alleles'].apply(lambda x: x[0])\n",
    "display(group1_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import counter\n",
    "from collections import Counter\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "for index, row in group1_df.iterrows():\n",
    "    peptides = row['peptide_sequence']\n",
    "    alleles = row['alleles']\n",
    "    prediction = predict_peptide_list(peptides)\n",
    "    predictions[row['donor_code']] = {'pred': dict(Counter(prediction)), 'tuedb': alleles}\n",
    "\n",
    "with open('predictions.txt', 'w') as file:\n",
    "    file.write(str(predictions))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.66\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "\n",
    "for donor in predictions:\n",
    "\n",
    "    tuedb = eval(predictions[donor]['tuedb'])\n",
    "\n",
    "    if len(tuedb) > 4 and len(tuedb) < 7:\n",
    "        pred = predictions[donor]['pred']\n",
    "\n",
    "        pred_a = {k: v for k, v in pred.items() if k.startswith('A')}\n",
    "        pred_b = {k: v for k, v in pred.items() if k.startswith('B')}\n",
    "        pred_c = {k: v for k, v in pred.items() if k.startswith('C')}\n",
    "\n",
    "        #pick the top 2 keys that have the highest value\n",
    "        pred_a = list(dict(sorted(pred_a.items(), key=lambda item: item[1], reverse=True)[:2]).keys())\n",
    "        pred_b = list(dict(sorted(pred_b.items(), key=lambda item: item[1], reverse=True)[:2]).keys())\n",
    "        pred_c = list(dict(sorted(pred_c.items(), key=lambda item: item[1], reverse=True)[:2]).keys())\n",
    "\n",
    "        prediction  = pred_a + pred_b + pred_c\n",
    "\n",
    "        matching_count = 0\n",
    "        for donor_allele in tuedb:\n",
    "            if donor_allele in prediction:\n",
    "                matching_count += 1\n",
    "\n",
    "        perc_matching = matching_count/len(tuedb)\n",
    "\n",
    "        accuracy = accuracy + [perc_matching]\n",
    "\n",
    "print(\"Accuracy:\", np.round(np.mean(accuracy),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epitopeprediction-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
